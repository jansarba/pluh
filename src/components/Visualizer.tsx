import { useRef, useEffect } from "react";
import { getOrCreateAnalyser, getAudioSampleRate } from "../audio/analyser";
import { fft, hannWindow } from "../audio/fft";
import styles from "./Visualizer.module.css";

// per AnalyserNode, the browser retains the most recent 32768 samples, so we have enough history
const FFT_SIZE = 2048;
const WAVEFORM_SECONDS = 0.8;
const MIN_FREQ = 20;
const MAX_FREQ = 20000;

// freq always shown on log scale so precompute log10
const LOG_MIN = Math.log10(MIN_FREQ);
const LOG_MAX = Math.log10(MAX_FREQ);

const MIN_DB = -90; //silence
const MAX_DB = 0;

// smoothing factor for fft display so it doesnt jitter amateurishly
const FFT_SMOOTHING = 0.7;

// just for drawing so quiet signals visible
const WAVEFORM_GAIN = 3;

const ROSE_KISS = "rgba(242, 108, 167, 0.25)"; 

interface Props {
  audioStarted: boolean;
  recordState: "idle" | "choosing" | "recording";
}

export function Visualizer({ audioStarted, recordState }: Props) {
  const fftRef = useRef<HTMLCanvasElement>(null);
  const waveRef = useRef<HTMLCanvasElement>(null);
  // rAF handle so we can cancel on unmount
  const rAFRef = useRef(0);
  // for smoothing
  const prevDbRef = useRef<Float32Array | null>(null);

  const recStartRef = useRef(0);
  const recStopRef = useRef(0);

  useEffect(() => {
    if (recordState === "recording") {
      recStartRef.current = performance.now();
      recStopRef.current = 0;
    } else if (recStartRef.current > 0 && recStopRef.current === 0) {
      //we were recording now were not snapshot stop state
      recStopRef.current = performance.now();
    }
  }, [recordState]);

  // ============================================================================
  //easy to get lost below so many comments generated by copilot 
  // to keep track of the structure and intent of the code.
  // The actual logic is pretty straightforward once you get past the comments.

  // ── main animation loop ─────────────────────────────────────────────────
  // Runs once when audioStarted flips to true. Sets up the animation frame
  // loop that redraws both canvases ~60 times per second.
  useEffect(() => {
    // Don't start drawing until Tone.js context is running
    if (!audioStarted) return;

    // Get (or lazily create) the Web Audio AnalyserNode connected to the limiter.
    // This is the only Tone.js interaction in this file — everything else is
    // raw Web Audio API and Canvas 2D.
    const analyser = getOrCreateAnalyser();

    // Native sample rate (typically 44100 or 48000 Hz)
    const sampleRate = getAudioSampleRate();

    // Reusable buffer for reading raw time-domain samples from the AnalyserNode.
    // Size matches analyser.fftSize (32768) — the browser fills this with the
    // most recent ~0.74s of audio as floating-point values in [-1, 1].
    const timeBuf = new Float32Array(analyser.fftSize);

    // Separate buffer for the 2048 samples we'll feed into our custom FFT
    const fftIn = new Float32Array(FFT_SIZE);

    // How many of the most-recent samples to draw in the waveform view.
    // Capped to the analyser's buffer length in case the sample rate is very high.
    const samplesToShow = Math.min(
      Math.round(WAVEFORM_SECONDS * sampleRate),
      analyser.fftSize
    );

    // ── per-frame draw callback ───────────────────────────────────────────
    function draw() {
      // Schedule ourselves for the next frame first (ensures smooth 60fps loop)
      rAFRef.current = requestAnimationFrame(draw);

      // Pull the latest time-domain snapshot from the Web Audio AnalyserNode.
      // This is a Web Audio API call — fills timeBuf with float samples [-1, 1].
      analyser.getFloatTimeDomainData(timeBuf);

      // Draw both canvases from the same time-domain buffer
      drawFFT(timeBuf, sampleRate);
      drawWave(timeBuf, samplesToShow);
    }

    // ── FFT (frequency spectrum) renderer ─────────────────────────────────
    // Takes the raw time-domain buffer and sample rate, runs your custom FFT,
    // and draws a log-frequency spectrum onto the FFT canvas.
    function drawFFT(buf: Float32Array, sr: number) {
      const cvs = fftRef.current;
      if (!cvs) return;
      // Get the 2D drawing context (the "!" asserts it's non-null)
      const ctx = cvs.getContext("2d")!;
      const w = cvs.width; // canvas pixel width  (CW = 360)
      const h = cvs.height; // canvas pixel height (CH = 160)

      // Wipe the canvas clean for this frame
      ctx.clearRect(0, 0, w, h);

      // ── prepare FFT input ─────────────────────────────────────────────
      // Copy the LAST 2048 samples from the 32768-sample buffer into fftIn.
      // Using the tail end gives us the most recent audio.
      const off = buf.length - FFT_SIZE;
      for (let i = 0; i < FFT_SIZE; i++) fftIn[i] = buf[off + i];

      // Apply Hann window in-place to reduce spectral leakage.
      // Without windowing, the abrupt start/end of the 2048-sample chunk
      // causes artificial high-frequency energy in the FFT output.
      hannWindow(fftIn);

      // Run your hand-written radix-2 FFT — returns a Float32Array of
      // 1025 magnitude values (positive-frequency half of the spectrum).
      const mag = fft(fftIn);

      // Frequency resolution: each FFT bin spans (sampleRate / FFT_SIZE) Hz.
      // At 44100 Hz / 2048 = ~21.5 Hz per bin.
      const binHz = sr / FFT_SIZE;

      // ── temporal smoothing state ──────────────────────────────────────
      // Lazily allocate or re-allocate the per-pixel smoothed dB array.
      // One float per horizontal pixel, initialized to silence (-90 dB).
      if (!prevDbRef.current || prevDbRef.current.length !== w) {
        prevDbRef.current = new Float32Array(w).fill(MIN_DB);
      }
      const prevDb = prevDbRef.current;

      // ── draw grid lines ───────────────────────────────────────────────
      // Vertical lines at 100 Hz, 1 kHz, 10 kHz (evenly spaced on log axis)
      ctx.strokeStyle = "rgba(0,0,0,0.06)";
      ctx.lineWidth = 1;
      for (const f of [100, 1000, 10000]) {
        // Convert frequency to x-pixel via the log10 mapping
        const x = ((Math.log10(f) - LOG_MIN) / (LOG_MAX - LOG_MIN)) * w;
        ctx.beginPath();
        ctx.moveTo(x, 0);
        ctx.lineTo(x, h);
        ctx.stroke();
      }
      // Horizontal lines at -60 dB and -30 dB
      for (const db of [-60, -30]) {
        // Convert dB to y-pixel (0 dB at top, -90 dB at bottom)
        const y = h - ((db - MIN_DB) / (MAX_DB - MIN_DB)) * h;
        ctx.beginPath();
        ctx.moveTo(0, y);
        ctx.lineTo(w, y);
        ctx.stroke();
      }

      // ── draw the spectrum curve ───────────────────────────────────────
      ctx.beginPath();
      ctx.strokeStyle = "rgba(94,74,227,0.75)"; // purple line
      ctx.lineWidth = 2;

      let started = false;
      // Iterate over every horizontal pixel of the canvas
      for (let px = 0; px < w; px++) {
        // Map this pixel to a frequency on a log10 scale.
        // px=0 → 20 Hz, px=w → 20000 Hz, with logarithmic distribution.
        const logF = LOG_MIN + (px / w) * (LOG_MAX - LOG_MIN);
        const freq = 10 ** logF;

        // Convert that frequency to a fractional FFT bin index
        const binF = freq / binHz;
        const b0 = Math.floor(binF);               // integer bin below
        const b1 = Math.min(b0 + 1, mag.length - 1); // integer bin above
        const t = binF - b0;                        // interpolation fraction

        // Linear interpolation between the two nearest FFT bins.
        // This smooths the spectrum curve since at low frequencies many pixels
        // map to the same bin, and at high frequencies bins are spread apart.
        const m = mag[b0] * (1 - t) + mag[b1] * t;

        // Convert magnitude to decibels: dB = 20 * log10(magnitude).
        // If magnitude is zero or negative, clamp to the silence floor.
        const rawDb = m > 0 ? 20 * Math.log10(m) : MIN_DB;

        // Apply exponential moving average (temporal smoothing).
        // 70% of the previous frame's value + 30% of the new value.
        // This prevents the line from jumping wildly frame-to-frame.
        const db = prevDb[px] * FFT_SMOOTHING + rawDb * (1 - FFT_SMOOTHING);
        prevDb[px] = db; // store for next frame

        // Convert dB to a y-pixel coordinate.
        // 0 dB maps to y=0 (top), -90 dB maps to y=h (bottom).
        const y =
          h - ((Math.max(db, MIN_DB) - MIN_DB) / (MAX_DB - MIN_DB)) * h;

        // Build the path — moveTo for the first point, lineTo for the rest
        if (!started) {
          ctx.moveTo(px, y);
          started = true;
        } else ctx.lineTo(px, y);
      }
      // Actually render the accumulated path to the canvas
      ctx.stroke();

      // ── draw frequency labels ─────────────────────────────────────────
      // Text labels "100", "1k", "10k" placed just right of their grid lines
      ctx.fillStyle = "rgba(0,0,0,0.18)";
      ctx.font = "16px monospace";
      ctx.textBaseline = "bottom";
      for (const [f, label] of [
        [100, "100"],
        [1000, "1k"],
        [10000, "10k"],
      ] as const) {
        const x = ((Math.log10(f) - LOG_MIN) / (LOG_MAX - LOG_MIN)) * w;
        ctx.fillText(label, x + 2, h - 2);
      }
    }

    // ── waveform (time-domain) renderer ───────────────────────────────────
    // Draws a scrolling amplitude envelope of the raw audio signal.
    // Uses min/max per pixel column for a clean, filled-bar look.
    function drawWave(buf: Float32Array, count: number) {
      const cvs = waveRef.current;
      if (!cvs) return;
      const ctx = cvs.getContext("2d")!;
      const w = cvs.width; // CW = 360
      const h = cvs.height; // CH = 160

      // Wipe canvas
      ctx.clearRect(0, 0, w, h);

      // Where in the 32768-sample buffer our display window starts.
      // We show the last `count` samples (the most recent audio).
      // The rightmost pixel = the newest sample; leftmost = oldest.
      const start = buf.length - count;
      const now = performance.now();

      // Actual duration the waveform spans (may be < WAVEFORM_SECONDS when
      // samplesToShow was clamped to analyser.fftSize)
      const visibleSec = count / sampleRate;

      // ── recording highlight ─────────────────────────────────────────
      // If a recording happened, draw a pink rectangle over the portion of
      // the waveform that corresponds to the recording time window.
      // As time advances, this highlight scrolls left and eventually off-screen.
      if (recStartRef.current > 0) {
        // How many seconds ago recording started
        const startAgo = (now - recStartRef.current) / 1000;
        // How many seconds ago recording stopped (0 if still recording)
        const stopAgo =
          recStopRef.current > 0
            ? (now - recStopRef.current) / 1000
            : 0;

        // Once the highlight has fully scrolled off the visible window, reset
        if (stopAgo >= visibleSec) {
          recStartRef.current = 0;
          recStopRef.current = 0;
        } else {
          // Convert "seconds ago" to pixel positions.
          // The right edge of the canvas is "now" (0 seconds ago).
          // The left edge is visibleSec ago.
          const rightAgo = stopAgo; // right edge of highlight
          const leftAgo = Math.min(startAgo, visibleSec); // clamp to visible range
          const pxRight = w * (1 - rightAgo / visibleSec);
          const pxLeft = w * (1 - leftAgo / visibleSec);
          if (pxRight > pxLeft) {
            ctx.fillStyle = ROSE_KISS;
            ctx.fillRect(pxLeft, 0, pxRight - pxLeft, h);
          }
        }
      }

      // ── center line (zero crossing reference) ─────────────────────────
      ctx.strokeStyle = "rgba(0,0,0,0.06)";
      ctx.lineWidth = 1;
      ctx.beginPath();
      ctx.moveTo(0, h / 2); // horizontal line at vertical center
      ctx.lineTo(w, h / 2);
      ctx.stroke();

      // How many audio samples are represented by each horizontal pixel.
      // At 44100 Hz, 0.8s, 360px: ~98 samples per pixel.
      const samplesPerPx = count / w;

      ctx.beginPath();
      ctx.strokeStyle = "rgba(0,0,0,0.45)"; // dark semi-transparent for the waveform
      ctx.lineWidth = 1.5;

      // ── min/max envelope rendering ────────────────────────────────────
      // For each pixel column, find the min and max sample values within
      // that pixel's sample range. Then draw a vertical line from min to max.
      // This produces the classic "waveform envelope" look, equivalent to
      // what you see in DAWs like Ableton or Audacity.
      for (let px = 0; px < w; px++) {
        // Sample range for this pixel column
        const s0 = start + Math.floor(px * samplesPerPx);
        const s1 = start + Math.floor((px + 1) * samplesPerPx);

        // Find min and max sample values in this range
        let mn = 1,   // will be driven down
          mx = -1;    // will be driven up
        for (let s = s0; s < s1 && s < buf.length; s++) {
          const v = buf[s];
          if (v < mn) mn = v;
          if (v > mx) mx = v;
        }

        // Apply gain boost and clamp to [-1, 1] so quiet signals are visible
        mn = Math.max(mn * WAVEFORM_GAIN, -1);
        mx = Math.min(mx * WAVEFORM_GAIN, 1);

        // Convert sample values [-1, 1] to y-pixel coordinates.
        // +1 maps to y=0 (top), -1 maps to y=h (bottom), 0 maps to h/2 (center).
        const yMin = ((1 - mx) / 2) * h; // max sample → topmost y (smallest y value)
        const yMax = ((1 - mn) / 2) * h; // min sample → bottommost y (largest y value)

        // Draw a vertical line segment for this pixel column
        ctx.moveTo(px, yMin);
        ctx.lineTo(px, yMax);
      }
      // Render all the vertical line segments at once
      ctx.stroke();
    }

    // ── kick off the loop ─────────────────────────────────────────────────
    draw();

    // Cleanup: cancel the animation frame when the component unmounts
    // or when audioStarted changes. Prevents memory leaks and orphaned loops.
    return () => cancelAnimationFrame(rAFRef.current);
  }, [audioStarted]); // Only re-run this effect when audioStarted changes

  return (
    <div className={styles.container} onClick={(e) => e.stopPropagation()}>
      <div className={styles.box}>
        <canvas ref={fftRef} className={styles.canvas} />
        <span className={styles.label}>freq</span>
      </div>
      <div className={styles.box}>
        <canvas
          ref={waveRef}
          className={styles.canvas}
        />
        <span className={styles.label}>wave</span>
      </div>
    </div>
  );
}
